---
title: Home
layout: page
---

# 2nd Workshop on Law, Society and Artificial Intelligence: Interdisciplinary perspectives on AI safety

{% include figure.html img="uidaho-workshop.jpg" alt="intro image here"  width="75%" %}


**June 9-10, 2025**<br>
Co-located with HHAI: The 4th International Conference Series on Hybrid Human-Artificial Intelligence<br> 
Pisa (PI), Italy
<br>
The LSAI Workshop aims to explore the interdisciplinary nature of AI Safety as a holistic field, recognizing its socio-technical, ethical, and legal implications, bringing together researchers and practitioners from diverse domains. The workshop seeks to encourage multilayered and diverse approaches to AI Safety, encouraging interdisciplinary discussions to critically examine how AI systems can be designed, deployed, and regulated in ways that prioritize safety, while also addressing broader societal and regulatory concerns.
This edition will focus on the multiple dimensions of AI Safety, including technical robustness, governance frameworks, ethical considerations, and socio-technical environments. Discussions will cover both theoretical and practical perspectives, exploring issues such as risk assessment, trust and acceptance of new technologies, accountability architectures, fairness, transparency, and the challenges of enforcing safety standards across jurisdictions. By addressing these themes, the workshop will highlight the necessity of a multidisciplinary approach to AI Safety, ensuring that technical solutions are aligned with societal values and regulatory requirements.
<br><br>
On the theme of AI Safety, this workshop recognized how it is increasingly presented as a critical issue due to the widespread deployment of AI systems in high-stakes domains such as healthcare, finance, transportation, and governance. The workshop argues that ensuring the reliability and trustworthiness of AI is not merely a technical challenge but also a societal imperative, and the complexity of AI systems and their integration into human decision-making processes necessitates a broader understanding of safety. Throughout the event, our goal is to encourage cross-contamination between ethical reasoning, legal constraints, social assessments and technical approaches.
<br><br>
In fact, a key objective of this workshop is to facilitate cross-pollination between disciplines, bringing together experts from social sciences, legal studies, ethics, and ICT. The workshop will create opportunities for novel insights and collaborative solutions by fostering dialogue between these diverse perspectives. This interdisciplinary exchange is essential for developing AI Safety strategies that are not only technically sound but also ethically responsible and legally enforceable. Through these discussions, the workshop aims to advance a more nuanced and holistic understanding of AI Safety, strengthening the bridge between theory and practice.


## Topics 
Relevant abstracts cover one or more of the following topics:
- Ethical, legal, and social issues in human-computer interaction.
- Automation and accountability in AI-based decision-making.
- Civil and criminal liability for AI-based systems.
- Explainable, interpretable, and transparent AI.
- Impact of general-purpose AI models.
- Legal and ethical frameworks for AI governance. 
- The development and deployment of AI in the legal domain.
- AI for Democracy and Legislative Action.
- AI, User Experience (UX) and User Interface (UI) design.

## Important Dates
{% include alert.html text="**Submission Deadline**: March 31st, 2025 (23:59 AoE)<br>
**Acceptance Notification**: May 2nd, 2025 (23:59 AoE)<br>
**Workshop day**: June 9-10, 2025" align="left" color="warning" %}

