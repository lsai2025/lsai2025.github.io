---
title: Home
layout: page
---

# 2nd Workshop on Law, Society and Artificial Intelligence: Interdisciplinary perspectives on AI safety
**June 10, 2025**<br>
Co-located with HHAI: The 4th International Conference Series on Hybrid Human-Artificial Intelligence<br> 
Pisa (PI), Italy
<br>
<br>
{% include alert.html text="** Submission Deadline Extended**: April 18th, 2025 (23:59 AoE)" align="left" color="warning" %}

The LSAI Workshop aims to explore the interdisciplinary nature of AI Safety, focusing on its socio-technical, ethical, and legal implications.
It will bring together researchers and practitioners from various fields to encourage diverse approaches to designing, deploying, and regulating AI systems that prioritize safety and align with societal values.
In line with the HHAI conference goals, the workshop will examine the intersections of AI Safety and HHAI, particularly focusing on AI systems designed to complement human abilities. Key discussions will include technical robustness, governance frameworks, ethical considerations, and human-AI collaboration, addressing challenges in sectors like healthcare, finance, transportation, and governance. 

The workshop will cover both theoretical and practical perspectives on AI Safety, contextualized within the field of HHAI.

## Topics 
Relevant abstracts cover one or more of the following topics:
- Technical robustness of AI systems working alongside humans
- Governance and regulatory frameworks for hybrid human-AI systems
- Ethical considerations in the design of AI systems that interact with people
- Trust, acceptance, and societal implications of AI technologies in high-stakes domains
- Transparency, fairness, and accountability architectures in human-AI collaboration
- Challenges in enforcing safety standards across jurisdictions and technologies

## Important Dates
{% include alert.html text="**Submission Deadline**: April 18th, 2025 (23:59 AoE)<br>
**Acceptance Notification**: May 2nd, 2025 (23:59 AoE)<br>
**Workshop day**: June 10, 2025" align="left" color="warning" %}

